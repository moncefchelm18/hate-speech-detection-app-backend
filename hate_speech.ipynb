{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afro american basho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Label\n",
       "0  denial of normal the con be asked to comment o...      1\n",
       "1  just by being able to tweet this insufferable ...      1\n",
       "2  that is retarded you too cute to be single tha...      1\n",
       "3  thought of a real badass mongol style declarat...      1\n",
       "4                                afro american basho      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_data = pd.read_csv('HateSpeechDatasetBalanced.csv')\n",
    "hate_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # to remove URLs\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s\\']', '', text)  # ro remove special characters\n",
    "    text = text.lower()  # converting to lowercase\n",
    "    return text\n",
    "\n",
    "hate_data['Content'] = hate_data['Content'].apply(clean_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afro american basho</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Label\n",
       "0  denial of normal the con be asked to comment o...      1\n",
       "1  just by being able to tweet this insufferable ...      1\n",
       "2  that is retarded you too cute to be single tha...      1\n",
       "3  thought of a real badass mongol style declarat...      1\n",
       "4                                afro american basho      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertin label to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = hate_data['Label'].values\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(hate_data['Content'], labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we do now text Tokenization and Sequence Padding so that we convert text data to numverical data so that nn model can undrestand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000  # Maximum number of words to consider\n",
    "max_len = 100  # Maximum length of a sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100, 64)           49408     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,362,497\n",
      "Trainable params: 1,362,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14523/14523 [==============================] - 1447s 99ms/step - loss: 0.3770 - accuracy: 0.8282 - val_loss: 0.3377 - val_accuracy: 0.8472\n",
      "Epoch 2/5\n",
      "14523/14523 [==============================] - 1458s 100ms/step - loss: 0.3142 - accuracy: 0.8599 - val_loss: 0.3200 - val_accuracy: 0.8568\n",
      "Epoch 3/5\n",
      "14523/14523 [==============================] - 1405s 97ms/step - loss: 0.2775 - accuracy: 0.8789 - val_loss: 0.3120 - val_accuracy: 0.8604\n",
      "Epoch 4/5\n",
      "14523/14523 [==============================] - 1411s 97ms/step - loss: 0.2474 - accuracy: 0.8940 - val_loss: 0.3156 - val_accuracy: 0.8641\n",
      "Epoch 5/5\n",
      "14523/14523 [==============================] - 1451s 100ms/step - loss: 0.2205 - accuracy: 0.9068 - val_loss: 0.3206 - val_accuracy: 0.8651\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4539/4539 [==============================] - 112s 25ms/step - loss: 0.3181 - accuracy: 0.8654\n",
      "Test Accuracy: 86.54%\n",
      "Test Loss: 0.3181\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_speech_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hate_speech_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model in TensorFlow SavedModel format\n",
    "model.save('hate_speech_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the model just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('hate_speech_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tokenizer using pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the tokinazeer just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tokenizer.pickle', 'rb') as handle:\n",
    "#     tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing with function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hate_speech(text, treshold):\n",
    "    \"\"\"\n",
    "    Function to predict if the given text is hate speech or not.\n",
    "    \"\"\"\n",
    "    # Clean the text\n",
    "    cleaned_text = clean_content(text)\n",
    "    \n",
    "    # Convert text to sequence using the tokenizer\n",
    "    seq = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    \n",
    "    # Pad the sequence to ensure consistent input size\n",
    "    padded_seq = pad_sequences(seq, maxlen=100)  # Adjust maxlen based on your training\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    prediction = model.predict(padded_seq)\n",
    "    print(prediction, \"xxxx\")\n",
    "    # Return the result\n",
    "    if prediction[0] > treshold:\n",
    "        return \"Hate Speech Detected\"\n",
    "    else:\n",
    "        return \"No Hate Speech Detected\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[0.7582519]] xxxx\n",
      "Text: 'The sun is shining brightly today, and it's a perfect day for a walk in the park ugly' => Prediction: Hate Speech Detected\n"
     ]
    }
   ],
   "source": [
    "# Test with some example phrases\n",
    "test_phrases = [\n",
    "    \"The sun is shining brightly today, and it's a perfect day for a walk in the park ugly\"\n",
    "]\n",
    "\n",
    "# Get predictions for each phrase\n",
    "for phrase in test_phrases:\n",
    "    result = predict_hate_speech(phrase, treshold=0.5)\n",
    "    print(f\"Text: '{phrase}' => Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploying api for this model using flusk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug: * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"Welcome to the Hate Speech Detection API!\"\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the text from the request\n",
    "    data = request.get_json()\n",
    "    text = data['text']\n",
    "\n",
    "    # Preprocess the input text\n",
    "    cleaned_text = clean_content(text)  # Assuming you have a clean_text function similar to the one used before\n",
    "    seq = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_seq = pad_sequences(seq, maxlen=100)\n",
    "\n",
    "    # Get the prediction from the model\n",
    "    prediction = model.predict(padded_seq)\n",
    "    \n",
    "    # Return the prediction as a JSON response\n",
    "    result = 'Hate Speech Detected' if prediction[0] > 0.5 else 'No Hate Speech Detected'\n",
    "    return jsonify({'prediction': result})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
